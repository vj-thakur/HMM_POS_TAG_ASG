{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi ALgorithm\n",
    "\n",
    "#### Date: 11-May-2020\n",
    "\n",
    "#### Project Description: Enhancement / imporvision of Vanilla Viterbi Algorithm.\n",
    "\n",
    "#### Operational Steps:\n",
    "1. Developing plain Vanilla Viterbi Algorithm.\n",
    "\n",
    "#### Techniques:\n",
    "2. Implication of Viterbi Modification Technique 1: following are the approach for the same:-\n",
    "   - Transition probability is considered in case of unknown words.\n",
    "   - The above approach is modified to consider transition probability weighted by tag occurrence probability in training set.\n",
    "3. Implication of Viterbi Modification Technique 2: following are the approach for the same:-\n",
    "   - backoff to a rule based tagger in case of an unknown word.\n",
    "   - The above technique is modified by using transition probability in approach 2 above if rule based tagger returns default noun tag ('NN').\n",
    "\n",
    "#### Validation\n",
    "4. The modified Viterbi algorithms are first tested on sampled test data for comparison.\n",
    "5. The final algorithm and vanilla Viterbi Algorithm are the tested on full testing data for comparison.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pprint, time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Mr.', 'NOUN'), ('Vinken', 'NOUN'), ('is', 'VERB'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Elsevier', 'NOUN'), ('N.V.', 'NOUN'), (',', '.'), ('the', 'DET'), ('Dutch', 'NOUN'), ('publishing', 'VERB'), ('group', 'NOUN'), ('.', '.')], [('Rudolph', 'NOUN'), ('Agnew', 'NOUN'), (',', '.'), ('55', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), ('and', 'CONJ'), ('former', 'ADJ'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Consolidated', 'NOUN'), ('Gold', 'NOUN'), ('Fields', 'NOUN'), ('PLC', 'NOUN'), (',', '.'), ('was', 'VERB'), ('named', 'VERB'), ('*-1', 'X'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('of', 'ADP'), ('this', 'DET'), ('British', 'ADJ'), ('industrial', 'ADJ'), ('conglomerate', 'NOUN'), ('.', '.')], [('A', 'DET'), ('form', 'NOUN'), ('of', 'ADP'), ('asbestos', 'NOUN'), ('once', 'ADV'), ('used', 'VERB'), ('*', 'X'), ('*', 'X'), ('to', 'PRT'), ('make', 'VERB'), ('Kent', 'NOUN'), ('cigarette', 'NOUN'), ('filters', 'NOUN'), ('has', 'VERB'), ('caused', 'VERB'), ('a', 'DET'), ('high', 'ADJ'), ('percentage', 'NOUN'), ('of', 'ADP'), ('cancer', 'NOUN'), ('deaths', 'NOUN'), ('among', 'ADP'), ('a', 'DET'), ('group', 'NOUN'), ('of', 'ADP'), ('workers', 'NOUN'), ('exposed', 'VERB'), ('*', 'X'), ('to', 'PRT'), ('it', 'PRON'), ('more', 'ADV'), ('than', 'ADP'), ('30', 'NUM'), ('years', 'NOUN'), ('ago', 'ADP'), (',', '.'), ('researchers', 'NOUN'), ('reported', 'VERB'), ('0', 'X'), ('*T*-1', 'X'), ('.', '.')], [('The', 'DET'), ('asbestos', 'NOUN'), ('fiber', 'NOUN'), (',', '.'), ('crocidolite', 'NOUN'), (',', '.'), ('is', 'VERB'), ('unusually', 'ADV'), ('resilient', 'ADJ'), ('once', 'ADP'), ('it', 'PRON'), ('enters', 'VERB'), ('the', 'DET'), ('lungs', 'NOUN'), (',', '.'), ('with', 'ADP'), ('even', 'ADV'), ('brief', 'ADJ'), ('exposures', 'NOUN'), ('to', 'PRT'), ('it', 'PRON'), ('causing', 'VERB'), ('symptoms', 'NOUN'), ('that', 'DET'), ('*T*-1', 'X'), ('show', 'VERB'), ('up', 'PRT'), ('decades', 'NOUN'), ('later', 'ADJ'), (',', '.'), ('researchers', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('*T*-2', 'X'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))\n",
    "\n",
    "# checking some tagged data from the data set\n",
    "print(nltk_data[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into training and test with ratio of 95:5\n",
    "train_set, test_set = train_test_split(nltk_data,train_size = 0.95, test_size = 0.05, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Tagged Words: \t 95547\n",
      "Test Tagged words: \t 5129\n",
      "Tagged words from train set: \t [('confirmed', 'VERB'), ('the', 'DET'), ('filing', 'NOUN'), ('but', 'CONJ')]\n",
      "No of unique tags: \t 12\n",
      "Unique Tags: \n",
      " {'PRON', 'DET', 'X', 'NUM', 'VERB', '.', 'ADP', 'NOUN', 'ADJ', 'PRT', 'CONJ', 'ADV'}\n",
      "count of words in vocab:\t 12100\n"
     ]
    }
   ],
   "source": [
    "# creating the list of train and test tagged words\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "test_tagged_words = [tup[0] for sent in test_set for tup in sent]\n",
    "\n",
    "# printing the details of the tagged words\n",
    "print('Train Tagged Words: \\t',len(train_tagged_words))\n",
    "print('Test Tagged words: \\t',len(test_tagged_words))\n",
    "\n",
    "#printing some of the tagged words from tain set.\n",
    "print('Tagged words from train set: \\t',train_tagged_words[1:5])\n",
    "\n",
    "# printing the list of unique tags in the data set:\n",
    "tags = {tag for word, tag in train_tagged_words}\n",
    "print('No of unique tags: \\t',len(tags))\n",
    "print('Unique Tags: \\n', tags)\n",
    "\n",
    "# printing the count of words present:\n",
    "vocab={word for word, tag in train_tagged_words}\n",
    "print('count of words in vocab:\\t',len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging algorithm using Hiddne Markov Model (HMM)\n",
    "\n",
    "Given a sequence of words to be tagged, the task is to assign the most probable tag to the wod. In other words, for every word \"w\" assign the tag \"t\" that maximises the likelihood P(t/w)\n",
    "\n",
    "Since P(t/w) = P(w/t). P(t) / P(w), after ignoring P(w), we have to compute P(w/t) and P(t).\n",
    "\n",
    "Now:\n",
    "\n",
    "- P(w/t): is the emission probability of a given word for a given tag. This can be computed based on the fraction of given word for given tag to the total count of that tag, ie: P(w/t) = count(w, t) / count(t).\n",
    "\n",
    "- P(t): is the probability of tag (also transition probability), and in a tagging task, we assume that a tag will depend only on the previous tag (Markov order 1 assumption). In other words, the probability of say a tag being NN will depend only on the previous tag t(n-1). So for e.g. if t(n-1) is a JJ, then t(n) is likely to be an NN since adjectives often precede a noun (blue coat, tall building etc.).\n",
    "\n",
    "**ref, HMM definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5284, 8281)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function to compute emission probabilities for the give word.\n",
    "def word_given_tag(word,tag,train_bag = train_tagged_words):\n",
    "    taglist = [pair for pair in train_bag if pair[1] == tag]\n",
    "    tag_count = len(taglist)\n",
    "    w_in_tag = [pair[0] for pair in taglist if pair[0] ==word]\n",
    "    word_count_given_tag = len(w_in_tag)\n",
    "    return(word_count_given_tag, tag_count)\n",
    "\n",
    "# fucntion to compute the transition probability of a previous and next tag\n",
    "def t2_given_t1(t2,t1,train_bag=train_tagged_words):\n",
    "    tags= [pair[1] for pair in train_bag]\n",
    "    t1_tags = [tag for tag in tags if tag==t1]\n",
    "    count_t1 = len(t1_tags)\n",
    "    t2_given_t1 = [tags[index+1] for index in range(len(tags)-1) if tags[index]==t1 and tags[index+1]==t2]\n",
    "    count_t2_given_t1 = len(t2_given_t1)\n",
    "    return (count_t2_given_t1,count_t1)\n",
    "\n",
    "## dummy Check\n",
    "t2_given_t1('NOUN','DET')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRON</th>\n",
       "      <th>DET</th>\n",
       "      <th>X</th>\n",
       "      <th>NUM</th>\n",
       "      <th>VERB</th>\n",
       "      <th>.</th>\n",
       "      <th>ADP</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>PRT</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>ADV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.007657</td>\n",
       "      <td>0.009954</td>\n",
       "      <td>0.089969</td>\n",
       "      <td>0.006508</td>\n",
       "      <td>0.485452</td>\n",
       "      <td>0.040965</td>\n",
       "      <td>0.022971</td>\n",
       "      <td>0.210949</td>\n",
       "      <td>0.073124</td>\n",
       "      <td>0.013017</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>0.034074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.003744</td>\n",
       "      <td>0.005676</td>\n",
       "      <td>0.045405</td>\n",
       "      <td>0.022220</td>\n",
       "      <td>0.039850</td>\n",
       "      <td>0.017993</td>\n",
       "      <td>0.009540</td>\n",
       "      <td>0.638087</td>\n",
       "      <td>0.204323</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.012438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.055538</td>\n",
       "      <td>0.054742</td>\n",
       "      <td>0.076384</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>0.203851</td>\n",
       "      <td>0.163590</td>\n",
       "      <td>0.142584</td>\n",
       "      <td>0.062381</td>\n",
       "      <td>0.017187</td>\n",
       "      <td>0.185232</td>\n",
       "      <td>0.010662</td>\n",
       "      <td>0.024984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.003276</td>\n",
       "      <td>0.210542</td>\n",
       "      <td>0.184932</td>\n",
       "      <td>0.018761</td>\n",
       "      <td>0.117332</td>\n",
       "      <td>0.036033</td>\n",
       "      <td>0.350208</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>0.026504</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.002978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.035786</td>\n",
       "      <td>0.134392</td>\n",
       "      <td>0.217506</td>\n",
       "      <td>0.022851</td>\n",
       "      <td>0.169249</td>\n",
       "      <td>0.034934</td>\n",
       "      <td>0.092022</td>\n",
       "      <td>0.110070</td>\n",
       "      <td>0.064988</td>\n",
       "      <td>0.030674</td>\n",
       "      <td>0.005577</td>\n",
       "      <td>0.081952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.066349</td>\n",
       "      <td>0.173335</td>\n",
       "      <td>0.026971</td>\n",
       "      <td>0.081003</td>\n",
       "      <td>0.089095</td>\n",
       "      <td>0.093320</td>\n",
       "      <td>0.091342</td>\n",
       "      <td>0.222242</td>\n",
       "      <td>0.043963</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.057538</td>\n",
       "      <td>0.052324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.070031</td>\n",
       "      <td>0.324709</td>\n",
       "      <td>0.034427</td>\n",
       "      <td>0.062226</td>\n",
       "      <td>0.008340</td>\n",
       "      <td>0.039025</td>\n",
       "      <td>0.016893</td>\n",
       "      <td>0.320967</td>\n",
       "      <td>0.107024</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.014006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.004607</td>\n",
       "      <td>0.012942</td>\n",
       "      <td>0.029175</td>\n",
       "      <td>0.009542</td>\n",
       "      <td>0.147667</td>\n",
       "      <td>0.240604</td>\n",
       "      <td>0.176514</td>\n",
       "      <td>0.263564</td>\n",
       "      <td>0.012248</td>\n",
       "      <td>0.043397</td>\n",
       "      <td>0.042666</td>\n",
       "      <td>0.017074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.004943</td>\n",
       "      <td>0.021091</td>\n",
       "      <td>0.021256</td>\n",
       "      <td>0.011699</td>\n",
       "      <td>0.063931</td>\n",
       "      <td>0.078267</td>\n",
       "      <td>0.699621</td>\n",
       "      <td>0.066403</td>\n",
       "      <td>0.010710</td>\n",
       "      <td>0.016971</td>\n",
       "      <td>0.004778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.017792</td>\n",
       "      <td>0.097858</td>\n",
       "      <td>0.013509</td>\n",
       "      <td>0.056672</td>\n",
       "      <td>0.405272</td>\n",
       "      <td>0.043822</td>\n",
       "      <td>0.020099</td>\n",
       "      <td>0.247776</td>\n",
       "      <td>0.083031</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>0.002306</td>\n",
       "      <td>0.010214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.058113</td>\n",
       "      <td>0.121339</td>\n",
       "      <td>0.008833</td>\n",
       "      <td>0.039981</td>\n",
       "      <td>0.156671</td>\n",
       "      <td>0.034868</td>\n",
       "      <td>0.052534</td>\n",
       "      <td>0.349140</td>\n",
       "      <td>0.118085</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.055323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.014906</td>\n",
       "      <td>0.069891</td>\n",
       "      <td>0.023186</td>\n",
       "      <td>0.030474</td>\n",
       "      <td>0.343491</td>\n",
       "      <td>0.137131</td>\n",
       "      <td>0.118582</td>\n",
       "      <td>0.031467</td>\n",
       "      <td>0.129182</td>\n",
       "      <td>0.014243</td>\n",
       "      <td>0.006956</td>\n",
       "      <td>0.080490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          PRON       DET         X       NUM      VERB         .       ADP  \\\n",
       "PRON  0.007657  0.009954  0.089969  0.006508  0.485452  0.040965  0.022971   \n",
       "DET   0.003744  0.005676  0.045405  0.022220  0.039850  0.017993  0.009540   \n",
       "X     0.055538  0.054742  0.076384  0.002864  0.203851  0.163590  0.142584   \n",
       "NUM   0.001489  0.003276  0.210542  0.184932  0.018761  0.117332  0.036033   \n",
       "VERB  0.035786  0.134392  0.217506  0.022851  0.169249  0.034934  0.092022   \n",
       ".     0.066349  0.173335  0.026971  0.081003  0.089095  0.093320  0.091342   \n",
       "ADP   0.070031  0.324709  0.034427  0.062226  0.008340  0.039025  0.016893   \n",
       "NOUN  0.004607  0.012942  0.029175  0.009542  0.147667  0.240604  0.176514   \n",
       "ADJ   0.000330  0.004943  0.021091  0.021256  0.011699  0.063931  0.078267   \n",
       "PRT   0.017792  0.097858  0.013509  0.056672  0.405272  0.043822  0.020099   \n",
       "CONJ  0.058113  0.121339  0.008833  0.039981  0.156671  0.034868  0.052534   \n",
       "ADV   0.014906  0.069891  0.023186  0.030474  0.343491  0.137131  0.118582   \n",
       "\n",
       "          NOUN       ADJ       PRT      CONJ       ADV  \n",
       "PRON  0.210949  0.073124  0.013017  0.005360  0.034074  \n",
       "DET   0.638087  0.204323  0.000242  0.000483  0.012438  \n",
       "X     0.062381  0.017187  0.185232  0.010662  0.024984  \n",
       "NUM   0.350208  0.034247  0.026504  0.013699  0.002978  \n",
       "VERB  0.110070  0.064988  0.030674  0.005577  0.081952  \n",
       ".     0.222242  0.043963  0.002427  0.057538  0.052324  \n",
       "ADP   0.320967  0.107024  0.001390  0.000962  0.014006  \n",
       "NOUN  0.263564  0.012248  0.043397  0.042666  0.017074  \n",
       "ADJ   0.699621  0.066403  0.010710  0.016971  0.004778  \n",
       "PRT   0.247776  0.083031  0.001647  0.002306  0.010214  \n",
       "CONJ  0.349140  0.118085  0.004649  0.000465  0.055323  \n",
       "ADV   0.031467  0.129182  0.014243  0.006956  0.080490  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating ixj transition matrix of tags\n",
    "# each column is t2, each row is t1\n",
    "# thus M(i, j) represents P(tj given ti)\n",
    "\n",
    "tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n",
    "for i, t1 in enumerate(list(tags)):\n",
    "    for j,t2 in enumerate(list(tags)):\n",
    "        tags_matrix[i,j] = t2_given_t1(t2,t1)[0]/t2_given_t1(t2,t1)[1]\n",
    "# tags_matrix\n",
    "# converting the matrix to DF for readibility ease.\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(tags), index = list(tags))\n",
    "tags_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viterbi Algorithm\n",
    "\n",
    "The steps are as follows:\n",
    "\n",
    "   -  Given a sequence of words iterate through the sequence for each word (starting from first word in sequence) \n",
    "   -  calculate the product of emission probabilties and transition probabilties for all possible tags.\n",
    "   -  assign the tag which has maximum probability and move to the next word in sequence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla Viterbi Algorithm\n",
    "def Viterbi(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    for key, word in enumerate(words):\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "        pmax = max(p)\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testin Viterbi algorithm\n",
    "random.seed(1234)\n",
    "# random 5 sents\n",
    "rndom = [random.randint(1,len(test_set)) for x in range(5)]\n",
    "#list of sents\n",
    "test_run = [test_set[i] for i in rndom]\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time lapsed:  36.299710512161255\n",
      "Vanilla Viterbi Algorithm Accuracy:  88.49557522123894\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(\"Time lapsed: \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Vanilla Viterbi Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Contra', 'PRON'), ('Contra', 'NOUN')),\n",
       " (('command', 'VERB'), ('command', 'NOUN')),\n",
       " (('Honduras', 'PRON'), ('Honduras', 'NOUN')),\n",
       " (('Sandinista', 'PRON'), ('Sandinista', 'NOUN')),\n",
       " (('offensive', 'PRON'), ('offensive', 'NOUN')),\n",
       " (('rebel', 'PRON'), ('rebel', 'NOUN')),\n",
       " (('forces', 'VERB'), ('forces', 'NOUN')),\n",
       " (('Bucking', 'PRON'), ('Bucking', 'VERB')),\n",
       " (('drew', 'PRON'), ('drew', 'VERB')),\n",
       " (('Eveready', 'PRON'), ('Eveready', 'NOUN')),\n",
       " (('*T*-252', 'PRON'), ('*T*-252', 'X')),\n",
       " (('complaining', 'PRON'), ('complaining', 'VERB')),\n",
       " (('up', 'ADV'), ('up', 'PRT'))]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking incorrectly tagged words\n",
    "[j for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0] != j[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viterbi Modification-Technique I\n",
    "\n",
    "- First solution for unknown words: assign based on transition probabilities only in case of unknown words as emission probability for unknown word is zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transition probability of tags when emission probability is zero (in case of unknown words)\n",
    "\n",
    "def Viterbi_1(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    for key, word in enumerate(words):\n",
    "        p = [] \n",
    "        p_transition =[] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            p_transition.append(transition_p)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        state_max = T[p.index(pmax)] \n",
    "        if(pmax==0):\n",
    "            pmax = max(p_transition)\n",
    "            state_max = T[p_transition.index(pmax)]\n",
    "        else:\n",
    "            state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time lapsed:  38.03657555580139\n",
      "Viterbi_1 Accuracy:  94.69026548672566\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tagged_seq = Viterbi_1(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(\"time lapsed: \", difference)\n",
    "check = [i for i,j in zip(tagged_seq, test_run_base) if i==j]\n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print(\"Viterbi_1 Accuracy: \", accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Tag occurance probability weights: \n",
    "applying weights based on the probability of tag occurance to the transition probabilities of tags and then use the resulting probability for predicting unknown words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PRON', 0.0273373313657153),\n",
       " ('DET', 0.08666938784053921),\n",
       " ('X', 0.06576867928872701),\n",
       " ('NUM', 0.035145007169246546),\n",
       " ('VERB', 0.1351167488251855),\n",
       " ('.', 0.11641391147812072),\n",
       " ('ADP', 0.0978889970381069),\n",
       " ('NOUN', 0.2862674913916711),\n",
       " ('ADJ', 0.06351847781719991),\n",
       " ('PRT', 0.03176447193527793),\n",
       " ('CONJ', 0.02251248076862696),\n",
       " ('ADV', 0.031597015081582885)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_prob = []\n",
    "total_tag = len([tag for word,tag in train_tagged_words])\n",
    "for t in tags:\n",
    "    each_tag = [tag for word,tag in train_tagged_words if tag==t]\n",
    "    tag_prob.append((t,len(each_tag)/total_tag))\n",
    "\n",
    "tag_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_1(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    for key, word in enumerate(words):\n",
    "        p = [] \n",
    "        p_transition =[]  \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            tag_p = [pair[1] for pair in tag_prob if pair[0]==tag ]\n",
    "            transition_p = tag_p[0]*transition_p             \n",
    "            p_transition.append(transition_p)\n",
    "        pmax = max(p)\n",
    "        state_max = T[p.index(pmax)] \n",
    "        if(pmax==0):\n",
    "            pmax = max(p_transition)\n",
    "            state_max = T[p_transition.index(pmax)]                 \n",
    "                           \n",
    "        else:\n",
    "            state_max = T[p.index(pmax)] \n",
    "        \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time lapsed:  37.99132752418518\n",
      "Modified Viterbi_1 Accuracy:  95.57522123893806\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_1(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(\"Time lapsed: \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Modified Viterbi_1 Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the weighted transition probabilites we have improved the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('command', 'VERB'), ('command', 'NOUN')),\n",
       " (('Sandinista', 'VERB'), ('Sandinista', 'NOUN')),\n",
       " (('Eveready', 'VERB'), ('Eveready', 'NOUN')),\n",
       " (('*T*-252', 'VERB'), ('*T*-252', 'X')),\n",
       " (('up', 'ADV'), ('up', 'PRT'))]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the incorrectly tagged words\n",
    "[j for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0] != j[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following list of words have been correctly POS tagged by Viterbi_1 as compared to vanilla Viterbi Algorithm:\n",
    "\n",
    "    Contra:correctly tagged as NOUN\n",
    "    Honduras:correctly tagged as NOUN\n",
    "    complaining: correctly tagged as VERB\n",
    "    Bucking: correctly tagged as VERB\n",
    "\n",
    "### Viterbi Modification-Technique II\n",
    "### second solution for unknown words:  backoff to rule based tagger\n",
    "   POS tag 'X' can be easily encapsulated in regex rule, so extraction is only based on ruled based tagged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify patterns for tagging\n",
    "patterns = [\n",
    "    (r'.*ing$', 'VERB'),              # gerund\n",
    "    (r'.*ed$', 'VERB'),               # past tense \n",
    "    (r'.*es$', 'VERB'),               # verb    \n",
    "    (r'.*\\'s$', 'NOUN'),              # possessive nouns\n",
    "    (r'.*s$', 'NOUN'),                # plural nouns\n",
    "    (r'\\*T?\\*?-[0-9]+$', 'X'),        # X\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), # cardinal numbers\n",
    "    (r'.*', 'NOUN')                   # nouns\n",
    "]\n",
    "\n",
    "# rule based tagger\n",
    "rule_based_tagger = nltk.RegexpTagger(patterns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modification in Viterbi Algorithm : Backoff to rule based tagger \n",
    "def Viterbi_2(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    for key, word in enumerate(words):\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "        pmax = max(p)\n",
    "        state_max = rule_based_tagger.tag([word])[0][1]       \n",
    "        if(pmax==0):\n",
    "            state_max = rule_based_tagger.tag([word])[0][1]\n",
    "        else:\n",
    "            if state_max != 'X':\n",
    "                state_max = T[p.index(pmax)]                \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time lapsed:  39.213961362838745\n",
      "Modified Viterbi_2 Accuracy:  97.34513274336283\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_2(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(\"Time lapsed: \", difference)\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Modified Viterbi_2 Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('command', 'VERB'), ('command', 'NOUN')),\n",
       " (('drew', 'NOUN'), ('drew', 'VERB')),\n",
       " (('up', 'ADV'), ('up', 'PRT'))]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the incorrectly tagged words\n",
    "[j for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0] != j[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The following list of words have been correctly POS tagged by Viterbi_2 as compared to vanilla Viterbi Algorithm:\n",
    "\n",
    "    Contra:correctly tagged as NOUN\n",
    "    Honduras:correctly tagged as NOUN\n",
    "    complaining: correctly tagged as VERB\n",
    "    Bucking: correctly tagged as VERB\n",
    "\n",
    "the following list of words has been correctly tagged by Viterbi_2 as compared to Viterbi_1\n",
    "\n",
    "    Sandinista: correctly tagged as NOUN\n",
    "    Eveready: correctly tagged as NOUN\n",
    "    *T*-252: correctly tagged as 'X'\n",
    "\n",
    "further modification in Viterb_2: We know that the rule based tagger assigns 'NOUN' by default if word does not fall in any rule, to correct this let's assign the tags for any such word based purely on transition probability of tags.\n",
    "\n",
    "So, first we will modify the rule based tagger to output 'NN' instead of 'NOUN' in case word does not satisfy any rules. We also observe that any capitalized word can still be defaulted as 'NOUN' so will add one more rule for that case.\n",
    "\n",
    "**ref, notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify patterns for tagging\n",
    "patterns = [\n",
    "    (r'.*ing$', 'VERB'),              # gerund\n",
    "    (r'.*ed$', 'VERB'),               # past tense \n",
    "    (r'.*es$', 'VERB'),               # verb    \n",
    "    (r'.*\\'s$', 'NOUN'),              # possessive nouns\n",
    "    (r'.*s$', 'NOUN'),                # plural nouns\n",
    "    (r'\\*T?\\*?-[0-9]+$', 'X'),        # X\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), # cardinal numbers\n",
    "    (r'^[A-Z][a-z].*', 'NOUN'),       # NOUN\n",
    "    (r'.*', 'NN')                     # default\n",
    "]\n",
    "\n",
    "# rule based tagger\n",
    "rule_based_tagger = nltk.RegexpTagger(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    " # modified Viterbi\n",
    "def Viterbi_2(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    for key, word in enumerate(words):\n",
    "        p = [] \n",
    "        p_transition =[] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            tag_p = [pair[1] for pair in tag_prob if pair[0]==tag ]\n",
    "            transition_p = tag_p[0]*transition_p\n",
    "            p_transition.append(transition_p)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        state_max = rule_based_tagger.tag([word])[0][1] \n",
    "        if(pmax==0):\n",
    "             if state_max == 'NN':\n",
    "                pmax = max(p_transition)\n",
    "                state_max = T[p_transition.index(pmax)]                 \n",
    "        else:\n",
    "             if state_max != 'X':\n",
    "                state_max = T[p.index(pmax)] \n",
    "        \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time lapsed:  37.195388078689575\n",
      "Modified Viterbi_2 Algorithm Accuracy:  98.23008849557522\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_2(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time lapsed: \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Modified Viterbi_2 Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('command', 'VERB'), ('command', 'NOUN')), (('up', 'ADV'), ('up', 'PRT'))]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the incorrectly tagged words\n",
    "[j for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0] != j[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The following list of words have been correctly POS tagged by Viterbi_2 as compared to vanilla Viterbi Algorithm:\n",
    "\n",
    "    Contra:correctly tagged as NOUN\n",
    "    Honduras:correctly tagged as NOUN\n",
    "    complaining: correctly tagged as VERB\n",
    "    Bucking: correctly tagged as VERB\n",
    "\n",
    "the following list of words has been correctly tagged by Viterbi_2 as compared to Viterbi_1\n",
    "\n",
    "    Sandinista: correctly tagged as NOUN\n",
    "    Eveready: correctly tagged as NOUN\n",
    "    *T*-252: correctly tagged as 'X'\n",
    "    drew: correctly tagged as VERB\n",
    "\n",
    "Evaluate vanilla Viterbi and modified Viterbi on entire test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tagged_words = [tup[0] for sent in test_set for tup in sent]\n",
    "test_run_base = [tup for sent in test_set for tup in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time lapsed:  1751.204689025879\n",
      "Modified Viterbi Algorithm Accuracy:  90.89491128875025\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(\"Time lapsed: \", difference)\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Modified Viterbi Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time lapsed:  1721.1713027954102\n",
      "Modified Viterbi1 Algorithm Accuracy:  94.46285825697018\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_1(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(\"Time lapsed: \", difference)\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Modified Viterbi1 Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_2(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(\"Time lapsed: \", difference)\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Modified Viterbi2 Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Test_sentences.txt')\n",
    "text = f.read()\n",
    "sample_test_sent = text.splitlines()\n",
    "f.close()\n",
    "sample_test_sent = test_sentences[:-3]\n",
    "sample_test_sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of untagged words\n",
    "sample_test_words = [word for sent in sample_test_sent for word in sent.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "sample_tagged_seq = Viterbi(sample_test_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time lapsed: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tagged_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We can see that several words have been misclassified by vanilla Viterbi POS tagger, for example:\n",
    "\n",
    "    Android as NUM\n",
    "    Google as NUM\n",
    "    OS as NUM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "sample_tagged_seq = Viterbi_2(sample_test_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time lapsed: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tagged_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "All these cases were correctly POS tagged by Viterbi_2:\n",
    "\n",
    "    Android as NOUN\n",
    "    Google as NOUN\n",
    "    OS as NOUN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm\n",
    "\n",
    "The accuracy of vanilla Viterbi Algorithm: 91.52%\n",
    "\n",
    "The accuracy of modified Viterbi Algorithm: 95.44%\n",
    "\n",
    "## List down cases which were incorrectly tagged by original POS tagger and got corrected by your modifications\n",
    "\n",
    "The following cases were incorrectly tagged which got corrected by modified Viterbi Algorithm:\n",
    "\n",
    "    Contra:correctly tagged as NOUN\n",
    "    Honduras:correctly tagged as NOUN\n",
    "    complaining: correctly tagged as VERB\n",
    "    Bucking: correctly tagged as VERB\n",
    "    Sandinista: correctly tagged as NOUN\n",
    "    Eveready: correctly tagged as NOUN\n",
    "    *T*-252: correctly tagged as 'X'\n",
    "    drew: correctly tagged as VERB\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
